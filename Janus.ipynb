{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimonfordont/DS_course/blob/main/Janus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i1tvmWXSUIVF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-CHPPvkXVw6",
        "outputId": "aa79d5fd-2057-4228-959a-56de22f17439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Janus'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 115 (delta 23), reused 22 (delta 14), pack-reused 74 (from 1)\u001b[K\n",
            "Receiving objects: 100% (115/115), 7.16 MiB | 13.16 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/deepseek-ai/Janus.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Janus\n",
        "!pip install -e .\n",
        "!pip install flash-attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIeDQ1ClXwL_",
        "outputId": "5ae0dfa9-bcd3-4e0e-9b94-b2319be611a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Janus\n",
            "Obtaining file:///content/Janus\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from janus==1.0.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.38.2 in /usr/local/lib/python3.11/dist-packages (from janus==1.0.0) (4.47.1)\n",
            "Requirement already satisfied: timm>=0.9.16 in /usr/local/lib/python3.11/dist-packages (from janus==1.0.0) (1.0.14)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from janus==1.0.0) (1.2.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from janus==1.0.0) (0.2.0)\n",
            "Collecting attrdict (from janus==1.0.0)\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from janus==1.0.0) (0.8.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.16->janus==1.0.0) (0.20.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.16->janus==1.0.0) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.16->janus==1.0.0) (0.27.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.16->janus==1.0.0) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->janus==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.1->janus==1.0.0) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.1->janus==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->janus==1.0.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->janus==1.0.0) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->janus==1.0.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->janus==1.0.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->janus==1.0.0) (0.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->janus==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->janus==1.0.0) (5.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from attrdict->janus==1.0.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.1->janus==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.38.2->janus==1.0.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.38.2->janus==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.38.2->janus==1.0.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.38.2->janus==1.0.0) (2024.12.14)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm>=0.9.16->janus==1.0.0) (11.1.0)\n",
            "Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: janus\n",
            "  Building editable for janus (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for janus: filename=janus-1.0.0-0.editable-py3-none-any.whl size=15926 sha256=81c8a693d32632578655905a42534ed5759624e4467f1b0decceada45eb90894\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iz1njyp8/wheels/04/ee/d6/76a460ef4080a263aa86cc3fdbb1c5bb29f559fbd8155d1c83\n",
            "Successfully built janus\n",
            "Installing collected packages: attrdict, janus\n",
            "Successfully installed attrdict-2.0.1 janus-1.0.0\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.3.tar.gz (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.5.1+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.3-cp311-cp311-linux_x86_64.whl size=191363917 sha256=b1243e9b86687348a5ab03a073abacdf8e3d5e9e4b7e5326a183f47348c5dfba\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/a3/f9/48d2706cb2eac05ec0dc144bf6954fe47bb3c2cd0de280765e\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "va3GDo1SLSG_",
        "outputId": "655c070a-4d5c-4e86-a34c-029c51e92410",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.13.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.7)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.6.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.6.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import AutoConfig, AutoModelForCausalLM\n",
        "from janus.models import MultiModalityCausalLM, VLChatProcessor\n",
        "from janus.utils.io import load_pil_images\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "# import spaces  # Import spaces for ZeroGPU compatibility\n",
        "\n",
        "\n",
        "# Load model and processor\n",
        "model_path = \"deepseek-ai/Janus-Pro-1B\"\n",
        "config = AutoConfig.from_pretrained(model_path)\n",
        "language_config = config.language_config\n",
        "language_config._attn_implementation = 'eager'\n",
        "vl_gpt = AutoModelForCausalLM.from_pretrained(model_path,\n",
        "                                             language_config=language_config,\n",
        "                                             trust_remote_code=True)\n",
        "if torch.cuda.is_available():\n",
        "    vl_gpt = vl_gpt.to(torch.bfloat16).cuda()\n",
        "else:\n",
        "    vl_gpt = vl_gpt.to(torch.float16)\n",
        "\n",
        "vl_chat_processor = VLChatProcessor.from_pretrained(model_path)\n",
        "tokenizer = vl_chat_processor.tokenizer\n",
        "cuda_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "@torch.inference_mode()\n",
        "# @spaces.GPU(duration=120)\n",
        "# Multimodal Understanding function\n",
        "def multimodal_understanding(image, question, seed, top_p, temperature):\n",
        "    # Clear CUDA cache before generating\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # set seed\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    conversation = [\n",
        "        {\n",
        "            \"role\": \"<|User|>\",\n",
        "            \"content\": f\"<image_placeholder>\\n{question}\",\n",
        "            \"images\": [image],\n",
        "        },\n",
        "        {\"role\": \"<|Assistant|>\", \"content\": \"\"},\n",
        "    ]\n",
        "\n",
        "    pil_images = [Image.fromarray(image)]\n",
        "    prepare_inputs = vl_chat_processor(\n",
        "        conversations=conversation, images=pil_images, force_batchify=True\n",
        "    ).to(cuda_device, dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16)\n",
        "\n",
        "\n",
        "    inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
        "\n",
        "    outputs = vl_gpt.language_model.generate(\n",
        "        inputs_embeds=inputs_embeds,\n",
        "        attention_mask=prepare_inputs.attention_mask,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        bos_token_id=tokenizer.bos_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        max_new_tokens=512,\n",
        "        do_sample=False if temperature == 0 else True,\n",
        "        use_cache=True,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "    )\n",
        "\n",
        "    answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "\n",
        "def generate(input_ids,\n",
        "             width,\n",
        "             height,\n",
        "             temperature: float = 1,\n",
        "             parallel_size: int = 5,\n",
        "             cfg_weight: float = 5,\n",
        "             image_token_num_per_image: int = 576,\n",
        "             patch_size: int = 16):\n",
        "    # Clear CUDA cache before generating\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    tokens = torch.zeros((parallel_size * 2, len(input_ids)), dtype=torch.int).to(cuda_device)\n",
        "    for i in range(parallel_size * 2):\n",
        "        tokens[i, :] = input_ids\n",
        "        if i % 2 != 0:\n",
        "            tokens[i, 1:-1] = vl_chat_processor.pad_id\n",
        "    inputs_embeds = vl_gpt.language_model.get_input_embeddings()(tokens)\n",
        "    generated_tokens = torch.zeros((parallel_size, image_token_num_per_image), dtype=torch.int).to(cuda_device)\n",
        "\n",
        "    pkv = None\n",
        "    for i in range(image_token_num_per_image):\n",
        "        with torch.no_grad():\n",
        "            outputs = vl_gpt.language_model.model(inputs_embeds=inputs_embeds,\n",
        "                                                use_cache=True,\n",
        "                                                past_key_values=pkv)\n",
        "            pkv = outputs.past_key_values\n",
        "            hidden_states = outputs.last_hidden_state\n",
        "            logits = vl_gpt.gen_head(hidden_states[:, -1, :])\n",
        "            logit_cond = logits[0::2, :]\n",
        "            logit_uncond = logits[1::2, :]\n",
        "            logits = logit_uncond + cfg_weight * (logit_cond - logit_uncond)\n",
        "            probs = torch.softmax(logits / temperature, dim=-1)\n",
        "            next_token = torch.multinomial(probs, num_samples=1)\n",
        "            generated_tokens[:, i] = next_token.squeeze(dim=-1)\n",
        "            next_token = torch.cat([next_token.unsqueeze(dim=1), next_token.unsqueeze(dim=1)], dim=1).view(-1)\n",
        "\n",
        "            img_embeds = vl_gpt.prepare_gen_img_embeds(next_token)\n",
        "            inputs_embeds = img_embeds.unsqueeze(dim=1)\n",
        "\n",
        "\n",
        "\n",
        "    patches = vl_gpt.gen_vision_model.decode_code(generated_tokens.to(dtype=torch.int),\n",
        "                                                 shape=[parallel_size, 8, width // patch_size, height // patch_size])\n",
        "\n",
        "    return generated_tokens.to(dtype=torch.int), patches\n",
        "\n",
        "def unpack(dec, width, height, parallel_size=5):\n",
        "    dec = dec.to(torch.float32).cpu().numpy().transpose(0, 2, 3, 1)\n",
        "    dec = np.clip((dec + 1) / 2 * 255, 0, 255)\n",
        "\n",
        "    visual_img = np.zeros((parallel_size, width, height, 3), dtype=np.uint8)\n",
        "    visual_img[:, :, :] = dec\n",
        "\n",
        "    return visual_img\n",
        "\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "# @spaces.GPU(duration=120)  # Specify a duration to avoid timeout\n",
        "def generate_image(prompt,\n",
        "                   seed=None,\n",
        "                   guidance=5,\n",
        "                   t2i_temperature=1.0):\n",
        "    # Clear CUDA cache and avoid tracking gradients\n",
        "    torch.cuda.empty_cache()\n",
        "    # Set the seed for reproducible results\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "    width = 384\n",
        "    height = 384\n",
        "    parallel_size = 5\n",
        "\n",
        "    with torch.no_grad():\n",
        "        messages = [{'role': '<|User|>', 'content': prompt},\n",
        "                    {'role': '<|Assistant|>', 'content': ''}]\n",
        "        text = vl_chat_processor.apply_sft_template_for_multi_turn_prompts(conversations=messages,\n",
        "                                                                   sft_format=vl_chat_processor.sft_format,\n",
        "                                                                   system_prompt='')\n",
        "        text = text + vl_chat_processor.image_start_tag\n",
        "\n",
        "        input_ids = torch.LongTensor(tokenizer.encode(text))\n",
        "        output, patches = generate(input_ids,\n",
        "                                   width // 16 * 16,\n",
        "                                   height // 16 * 16,\n",
        "                                   cfg_weight=guidance,\n",
        "                                   parallel_size=parallel_size,\n",
        "                                   temperature=t2i_temperature)\n",
        "        images = unpack(patches,\n",
        "                        width // 16 * 16,\n",
        "                        height // 16 * 16,\n",
        "                        parallel_size=parallel_size)\n",
        "\n",
        "        return [Image.fromarray(images[i]).resize((768, 768), Image.LANCZOS) for i in range(parallel_size)]\n",
        "\n",
        "\n",
        "# Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(value=\"# Multimodal Understanding\")\n",
        "    with gr.Row():\n",
        "        image_input = gr.Image()\n",
        "        with gr.Column():\n",
        "            question_input = gr.Textbox(label=\"Question\")\n",
        "            und_seed_input = gr.Number(label=\"Seed\", precision=0, value=42)\n",
        "            top_p = gr.Slider(minimum=0, maximum=1, value=0.95, step=0.05, label=\"top_p\")\n",
        "            temperature = gr.Slider(minimum=0, maximum=1, value=0.1, step=0.05, label=\"temperature\")\n",
        "\n",
        "    understanding_button = gr.Button(\"Chat\")\n",
        "    understanding_output = gr.Textbox(label=\"Response\")\n",
        "\n",
        "\n",
        "    gr.Markdown(value=\"# Text-to-Image Generation\")\n",
        "\n",
        "\n",
        "\n",
        "    with gr.Row():\n",
        "        cfg_weight_input = gr.Slider(minimum=1, maximum=10, value=5, step=0.5, label=\"CFG Weight\")\n",
        "        t2i_temperature = gr.Slider(minimum=0, maximum=1, value=1.0, step=0.05, label=\"temperature\")\n",
        "\n",
        "    prompt_input = gr.Textbox(label=\"Prompt. (Prompt in more detail can help produce better images!)\")\n",
        "    seed_input = gr.Number(label=\"Seed (Optional)\", precision=0, value=12345)\n",
        "\n",
        "    generation_button = gr.Button(\"Generate Images\")\n",
        "\n",
        "    image_output = gr.Gallery(label=\"Generated Images\", columns=2, rows=2, height=300)\n",
        "\n",
        "\n",
        "\n",
        "    understanding_button.click(\n",
        "        multimodal_understanding,\n",
        "        inputs=[image_input, question_input, und_seed_input, top_p, temperature],\n",
        "        outputs=understanding_output\n",
        "    )\n",
        "\n",
        "    generation_button.click(\n",
        "        fn=generate_image,\n",
        "        inputs=[prompt_input, seed_input, cfg_weight_input, t2i_temperature],\n",
        "        outputs=image_output\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)\n",
        "# demo.queue(concurrency_count=1, max_size=10).launch(server_name=\"0.0.0.0\", server_port=37906, root_path=\"/path\")"
      ],
      "metadata": {
        "id": "WZR2si6fLmq2",
        "outputId": "fb59802b-d487-468a-ccea-c0fb08fa1d95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some kwargs in processor config are unused and will not have any effect: ignore_id, image_tag, num_image_tokens, add_special_token, sft_format, mask_prompt. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b0d3c7bd413b29ce52.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b0d3c7bd413b29ce52.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}