{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimonfordont/DS_course/blob/main/Neural_networks/CV/Segementation/Breast_cancer_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Breast cancer segmentation"
      ],
      "metadata": {
        "id": "_tefKznypsjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs & Imports"
      ],
      "metadata": {
        "id": "jTv3BR0Kpy-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#pip install catalyst"
      ],
      "metadata": {
        "id": "I5hcmaD1q9_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKcJjREvpr7Q"
      },
      "outputs": [],
      "source": [
        "#import albumentations as albs\n",
        "import cv2\n",
        "import io\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "from IPython import display\n",
        "\n",
        "#from catalyst import dl, utils"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ],
      "metadata": {
        "id": "dxGci2D2p5sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -JLO 'https://www.dropbox.com/scl/fi/gs3kzp6b8k6faf667m5tt/breast-cancer-cells-segmentation.zip?rlkey=md3mzikpwrvnaluxnhms7r4zn'\n",
        "!unzip breast-cancer-cells-segmentation.zip"
      ],
      "metadata": {
        "id": "4SFKpRCfp7kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "O38iqK2tqEuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip breast-cancer-cells-segmentation.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KynwlwcA-w-Y",
        "outputId": "64c98bbb-3ae0-49a3-d6c2-d89a0576ef76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  breast-cancer-cells-segmentation.zip\n",
            "replace Images/ytma10_010704_benign1_ccd.tif? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = glob(os.path.join(\"/content/Images\", \"*.tif\"))"
      ],
      "metadata": {
        "id": "AYRjEmQqBi_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "hWQ1qRHTDQmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masks = [os.path.join(\"/content/Masks\", i.rsplit(\"/\",1)[-1].split(\"_ccd\")[0]+\".TIF\") for i in imgs]"
      ],
      "metadata": {
        "id": "l6d8ufsDBjwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(masks)"
      ],
      "metadata": {
        "id": "gfzfGtiDCn4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_tuples = list(zip(imgs, masks))\n",
        "random.shuffle(dataset_tuples)\n",
        "train_tuples, test_tuples = train_test_split(dataset_tuples)"
      ],
      "metadata": {
        "id": "PqO6GonPNSA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fs8Rkhu9NSSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write Dataloaders and transform data"
      ],
      "metadata": {
        "id": "vLylWtVwqAzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 512"
      ],
      "metadata": {
        "id": "ZYWACgIaQYYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BreastDataset(Dataset):\n",
        "\n",
        "    def __init__(self, img_mask):\n",
        "        self.img_mask = img_mask\n",
        "\n",
        "    def __len__(self,):\n",
        "        return len(self.img_mask)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, mask_path = self.img_mask[idx]\n",
        "        image = self.get_transform(img_path)\n",
        "        mask = self.get_transform(mask_path, normalize=False)\n",
        "        mask[mask > 0] = 1\n",
        "        return image,mask\n",
        "\n",
        "    def transform_image(self, path, normalize=True,resize=(SIZE, SIZE)):\n",
        "       image = io.imread(path)\n",
        "       image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "       image = cv2.resize(image, resize)\n",
        "       if normalize:\n",
        "          return image/255\n",
        "       return image"
      ],
      "metadata": {
        "id": "3swsl_vkQQvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BreastDataset(train_tuples)\n",
        "test_dataset = BreastDataset(test_tuples)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "rbjzHisXQnSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4zCL5HoWTTJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get unet model"
      ],
      "metadata": {
        "id": "-fKXCx1zh3Rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create double convolution block"
      ],
      "metadata": {
        "id": "p7A_ib86iwl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module)\n",
        "    def __init__(self, inch, ouch, kernel=3, padding=1):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(inch, ouch, kernel, padding=padding),\n",
        "            nn.BatchNorm2d(ouch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ouch, ouch, kernel, padding=padding),\n",
        "            nn.BatchNorm2d(ouch),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "d0MeCXdhTTY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder part"
      ],
      "metadata": {
        "id": "GP5fgPp7Oijk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, inch, ouch):\n",
        "    super().__init__()\n",
        "    self.enconv = nn.Sequential(nn.MaxPool2d(2),\n",
        "                                DoubleConv(inch, ouch))\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = self.enconv(x)\n",
        "      return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "ogVVtNrRTC2p",
        "outputId": "e5bd7ebc-746d-4e68-def3-da2ae55f224a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-198ea377f0ee>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-198ea377f0ee>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def __i\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder part"
      ],
      "metadata": {
        "id": "1WuwALGwOn6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, inch, ouch):\n",
        "    super().__init__()\n",
        "    self.upscaler = nn.ConvTranspose2d(inch, ouch//2, kernel_size=2, stride=2)\n",
        "    self.conv = DoubleConv(inch, ouch)\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "      x1 = self.upscaler(x1)\n",
        "      x1s = x1.size()\n",
        "      x2s = x2.size()\n",
        "      Xdiff = x2s[3] - x1s[3]\n",
        "      Ydiff = x2s[2] - x1s[2]\n",
        "      mdiffX = Xdiff - Xdiff//2\n",
        "      mdiffY = Ydiff - Ydiff//2\n",
        "      x1 = F.pad(x1, [Xdiff//2, mdiffX, Ydiff//2, mdiffY])\n",
        "      x = torch.cat([x2, x1], dim=1)\n",
        "      x = self.conv(x)\n",
        "      return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "WJsfa1viV9Pg",
        "outputId": "6bbc4885-49d9-42d6-f174-3062174f23a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8b2e03efc8f0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     self.deconv = nn.Sequential(nn.ConvTranspose2d(inch, inch//2, \n\u001b[1;32m      5\u001b[0m                                                    \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Basic output convolution layer"
      ],
      "metadata": {
        "id": "nQ7TonrBTBJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvOut(nn.Module):\n",
        "  def __init__(self, inch, ouch):\n",
        "    super(ConvOut, self).__init__()\n",
        "    self.conv = nn.Conv2d(inch, ouch, kernel_size=1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "NlGt-Onuiqhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### combine it all together"
      ],
      "metadata": {
        "id": "bNJf96LZFQd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet(nn.Module):\n",
        "  def __init__(self, n_in, n_out):\n",
        "    super(Unet, self).__init__()\n",
        "    self.n_channels = n_in\n",
        "    self.n_classes = n_out\n",
        "    d64, d128, d256, d512, d1k = 64, 128, 256, 512, 1024\n",
        "\n",
        "    self.inc = DoubleConv(n_in, d64)\n",
        "    self.enc1 = Encoder(d64, d128)\n",
        "    self.enc2 = Encoder(d128, d256)\n",
        "    self.enc3 = Encoder(d256, d512)\n",
        "    self.enc4 = Encoder(d512, d1k)\n",
        "\n",
        "    self.dec4 = Decoder(d1k, d512)\n",
        "    self.dec3 = Decoder(d512, d256)\n",
        "    self.dec2 = Decoder(d256, d128)\n",
        "    self.dec1 = Decoder(d128, d64)\n",
        "\n",
        "    self.out = ConvOut(d64, n_out)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.inc(x)\n",
        "    x2 = self.enc1(x1)\n",
        "    x3 = self.enc2(x2)\n",
        "    x4 = self.enc3(x3)\n",
        "    x = self.enc4(x4)\n",
        "\n",
        "    x = self.dec4(x, x4)\n",
        "    x = self.dec3(x, x3)\n",
        "    x = self.dec2(x, x2)\n",
        "    x = self.dec1(x, x1)\n",
        "\n",
        "    x = self.out(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "QMYsbAMeiqwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set a config"
      ],
      "metadata": {
        "id": "YpEBtYwIS9jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "  epochs = 10\n",
        "  lr = 4e-4\n",
        "  scheduler = False\n",
        "  wandb = False\n",
        "  device = lambda: \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  input_size = 224"
      ],
      "metadata": {
        "id": "MWKMzxlVR5D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_setup(model=False, optimizer=False, loss=False):\n",
        "  model = model or Unet(n_in=3, n_out=1)\n",
        "  model.to(CFG.device())\n",
        "  optimizer = optimizer or torch.optim.Adam(model.parameters(), lr=CFG.lr)\n",
        "  criterion = loss or nn.BCEWithLogitsLoss()\n",
        "  return, model, optimizer, criterion"
      ],
      "metadata": {
        "id": "vFI6Pfdhm5qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, optimizer, criterion = get_setup()"
      ],
      "metadata": {
        "id": "3_qwqlignWXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train loop"
      ],
      "metadata": {
        "id": "TKqwJW5ICgjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, traindata):\n",
        "  mpdel.train()\n",
        "  for epoch in tqdm(CFG.epochs):\n",
        "    for imgs, lbls in iter(traindata):\n",
        "      imgs = imgs.to(CFG.device()).permute(0, 3, 2, 1).float()\n",
        "      lbls = lbls.to(CFG.device()).permute(0, 3, 2, 1).float()\n",
        "      lbls = lbls.sum(1, keepdim=True).bool().float()\n",
        "      with optimizer.zero_grad():\n",
        "\n",
        "        logits = model(imgs)\n",
        "        loss = criterion(logits, lbls)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "  return model"
      ],
      "metadata": {
        "id": "mkXy4hXWCjFa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}